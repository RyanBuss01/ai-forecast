{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Dense, LSTM, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import os\n",
    "import requests\n",
    "import json\n",
    "api_key = os.getenv(\"API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = f\"https://api.oikolab.com/weather\"\n",
    "response = requests.get(url,\n",
    "    params={'param': 'temperature',\n",
    "            'location': 'Toronto, Ontario',\n",
    "            'start': '1990-01-01',\n",
    "            'end': '2020-12-31'},\n",
    "    headers={'api-key': api_key}\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if response.status_code == 200:\n",
    "    data = response.json()\n",
    "    print('Success:', response.text)\n",
    "else:\n",
    "    print(\"Error:\", response.status_code, response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/json/data.json', 'w') as f:\n",
    "    json.dump(data, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/json/data.json', 'r') as f:\n",
    "    js = json.load(f)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       coordinates (lat,lon) model (name)  \\\n",
      "1990-01-01 00:00:00  (43.653482, -79.383935)         era5   \n",
      "1990-01-01 01:00:00  (43.653482, -79.383935)         era5   \n",
      "1990-01-01 02:00:00  (43.653482, -79.383935)         era5   \n",
      "1990-01-01 03:00:00  (43.653482, -79.383935)         era5   \n",
      "1990-01-01 04:00:00  (43.653482, -79.383935)         era5   \n",
      "\n",
      "                     model elevation (surface)  utc_offset (hrs)  \\\n",
      "1990-01-01 00:00:00                     127.19              -5.0   \n",
      "1990-01-01 01:00:00                     127.19              -5.0   \n",
      "1990-01-01 02:00:00                     127.19              -5.0   \n",
      "1990-01-01 03:00:00                     127.19              -5.0   \n",
      "1990-01-01 04:00:00                     127.19              -5.0   \n",
      "\n",
      "                     temperature (degC)  \n",
      "1990-01-01 00:00:00                2.37  \n",
      "1990-01-01 01:00:00                2.07  \n",
      "1990-01-01 02:00:00                1.82  \n",
      "1990-01-01 03:00:00                1.13  \n",
      "1990-01-01 04:00:00                0.92  \n"
     ]
    }
   ],
   "source": [
    "data = json.loads(js['data'])\n",
    "\n",
    "\n",
    "df = pd.DataFrame(index=pd.to_datetime(data['index'], unit='s'),\n",
    "                  data=data['data'],\n",
    "                  columns=data['columns'])\n",
    "\n",
    "print(df.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the temperature to fahrenheit\n",
    "df['temperature (degF)'] = df['temperature (degC)'] * 9/5 + 32\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "temperature_scaled = scaler.fit_transform(df[['temperature (degF)']].values)\n",
    "window_size = 24 * 7  # Number of past days to use for predicting the next day's temperature\n",
    "\n",
    "# Create sequences\n",
    "def create_sequences(temperatures, window_size):\n",
    "    X, y = [], []\n",
    "    for i in range(len(temperatures) - window_size):\n",
    "        X.append(temperatures[i:i + window_size])\n",
    "        y.append(temperatures[i + window_size])\n",
    "    return np.array(X), np.array(y).reshape(-1, 1)\n",
    "\n",
    "\n",
    "# Use the normalized temperature data for creating sequences\n",
    "X, y = create_sequences(temperature_scaled, window_size)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "# It's important not to shuffle time series data to maintain the temporal sequence\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    LSTM(100, activation='relu', input_shape=(X.shape[1], X.shape[2])),  # Increased complexity\n",
    "    Dense(1)\n",
    "])\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.0005)\n",
    "\n",
    "model.compile(optimizer=optimizer, loss='mean_squared_error'); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "5432/5432 [==============================] - 272s 50ms/step - loss: 0.0014 - val_loss: 1.9144e-04\n",
      "Epoch 2/10\n",
      "5432/5432 [==============================] - 271s 50ms/step - loss: 1.3371e-04 - val_loss: 1.1759e-04\n",
      "Epoch 3/10\n",
      "5432/5432 [==============================] - 272s 50ms/step - loss: 1.0827e-04 - val_loss: 1.2125e-04\n",
      "Epoch 4/10\n",
      "5432/5432 [==============================] - 273s 50ms/step - loss: 9.9905e-05 - val_loss: 9.1131e-05\n",
      "Epoch 5/10\n",
      "5432/5432 [==============================] - 274s 51ms/step - loss: 9.5974e-05 - val_loss: 1.0010e-04\n",
      "Epoch 6/10\n",
      "5432/5432 [==============================] - 273s 50ms/step - loss: 9.4169e-05 - val_loss: 9.0243e-05\n",
      "Epoch 7/10\n",
      "5432/5432 [==============================] - 273s 50ms/step - loss: 9.2582e-05 - val_loss: 8.7425e-05\n",
      "Epoch 8/10\n",
      "5432/5432 [==============================] - 272s 50ms/step - loss: 9.1420e-05 - val_loss: 1.0143e-04\n",
      "Epoch 9/10\n",
      "5432/5432 [==============================] - 271s 50ms/step - loss: 9.0391e-05 - val_loss: 9.8111e-05\n",
      "Epoch 10/10\n",
      "5432/5432 [==============================] - 270s 50ms/step - loss: 8.8413e-05 - val_loss: 8.6011e-05\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x29ee59210>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=10, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 106ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Predicted temperatures for the next 7 days (168 hours):\n",
      "[33.905483 33.465523 32.93237  32.36006  31.856512 31.449577 31.093943\n",
      " 30.74793  30.38072  29.983288 29.567554 29.189505 28.889853 28.71249\n",
      " 28.699726 29.057108 29.613482 30.218462 30.660345 31.048437 31.342964\n",
      " 31.511099 31.55764  31.520348 31.632812 31.750515 31.692804 31.485434\n",
      " 31.19603  30.9337   30.688753 30.428375 30.124617 29.769613 29.36868\n",
      " 28.976622 28.639866 28.408974 28.334661 28.62235  29.17342  29.870655\n",
      " 30.356354 30.791862 31.151985 31.40695  31.543188 31.5776   31.644724\n",
      " 31.894737 31.999704 31.925186 31.72284  31.478962 31.256958 31.029312\n",
      " 30.77394  30.47526  30.123055 29.729126 29.365519 29.083199 28.940039\n",
      " 28.995169 29.43771  30.053774 30.585695 31.016705 31.395296 31.695274\n",
      " 31.895023 31.993677 32.00877  32.12284  32.329357 32.36595  32.251537\n",
      " 32.03664  31.822996 31.60927  31.378088 31.112293 30.805655 30.456772\n",
      " 30.064024 29.640675 29.280916 29.046934 28.997704 29.33976  29.838083\n",
      " 30.359224 30.763668 31.126137 31.418467 31.623474 31.739443 31.77851\n",
      " 31.905153 32.157284 32.254864 32.199493 32.026886 31.84357  31.65178\n",
      " 31.434748 31.17937  30.877851 30.530128 30.135283 29.752417 29.441813\n",
      " 29.255169 29.237486 29.489996 29.862064 30.277508 30.633867 30.957327\n",
      " 31.231388 31.438799 31.572039 31.640137 31.808924 32.070873 32.19186\n",
      " 32.1752   32.04439  31.89518  31.723219 31.52119  31.278934 30.993448\n",
      " 30.66158  30.286402 29.897444 29.542143 29.248777 29.04251  28.939703\n",
      " 28.960155 29.012175 29.075632 29.130678 29.254656 29.42953  29.589462\n",
      " 29.714834 29.856041 29.984156 30.07366  30.115946 30.083698 30.001528\n",
      " 29.867895 29.692846 29.460886 29.17913  28.85049  28.489304 28.128454\n",
      " 27.788744 27.491426 27.257965 27.11021  27.065199 27.119726 27.16562 ]\n"
     ]
    }
   ],
   "source": [
    "latest_data = scaler.transform(df[['temperature (degF)']].values)[-window_size:].reshape((1, window_size, 1))\n",
    "predicted_temperatures_normalized = []\n",
    "\n",
    "# Recursive prediction\n",
    "for _ in range(window_size):\n",
    "    # Predict the next step\n",
    "    next_step_normalized = model.predict(latest_data)\n",
    "    \n",
    "    # Store the normalized prediction\n",
    "    predicted_temperatures_normalized.append(next_step_normalized[0, 0])\n",
    "    \n",
    "    # Update the input sequence with the new prediction\n",
    "    # This moves the window one step forward by inserting the predicted value\n",
    "    latest_data = np.roll(latest_data, -1, axis=1)\n",
    "    latest_data[0, -1, 0] = next_step_normalized[0, 0]\n",
    "\n",
    "# Convert normalized predictions back to the original scale (degrees Fahrenheit)\n",
    "predicted_temperatures = scaler.inverse_transform(np.array(predicted_temperatures_normalized).reshape(-1, 1)).flatten()\n",
    "\n",
    "print(\"Predicted temperatures for the next 7 days (168 hours):\")\n",
    "print(predicted_temperatures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('data/model/h5/model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('data/model/h5/model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_2 (LSTM)               (None, 100)               40800     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 24)                2424      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 43,224\n",
      "Trainable params: 43,224\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will print out the signatures of your model\n",
    "print(list(model.signatures.keys()))\n",
    "\n",
    "# Assuming 'serving_default' is a key, you can then inspect a specific signature\n",
    "serving_default = model.signatures['serving_default']\n",
    "print(serving_default)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
